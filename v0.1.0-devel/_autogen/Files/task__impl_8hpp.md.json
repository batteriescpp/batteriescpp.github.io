{
  "abstract": false,
  "anchor": "#file-task-impl.hpp",
  "category": "files",
  "const": false,
  "defines": [
    {
      "abstract": false,
      "anchor": "#define-batteries-async-task-impl-hpp",
      "category": "defines",
      "const": false,
      "definition": "",
      "explicit": false,
      "fullname": "BATTERIES_ASYNC_TASK_IMPL_HPP",
      "hasDetails": false,
      "inline": false,
      "kind": "define",
      "language": "cpp",
      "location": {
        "bodyFile": "batteries/async/task_impl.hpp",
        "bodyStart": 6,
        "column": 9,
        "file": "batteries/async/task_impl.hpp",
        "line": 6
      },
      "name": "BATTERIES_ASYNC_TASK_IMPL_HPP",
      "override": false,
      "refid": "task__impl_8hpp_1aa56682c44d1e397f9744438a7d29d527",
      "static": false,
      "strong": false,
      "title": "BATTERIES_ASYNC_TASK_IMPL_HPP",
      "url": "/_autogen/Files/task__impl_8hpp/#define-batteries-async-task-impl-hpp",
      "visibility": "public"
    }
  ],
  "definition": "",
  "explicit": false,
  "fullname": "batteries/async/task_impl.hpp",
  "hasAdditionalMembers": false,
  "hasDetails": false,
  "includes": "<batteries/config.hpp>",
  "inline": false,
  "kind": "file",
  "language": "cpp",
  "location": {
    "column": 0,
    "file": "batteries/async/task_impl.hpp",
    "line": 0
  },
  "name": "batteries/async/task_impl.hpp",
  "namespaces": [
    {
      "anchor": "",
      "category": "namespaces",
      "fullname": "batt",
      "kind": "namespace",
      "language": "cpp",
      "name": "batt",
      "refid": "namespacebatt",
      "title": "batt",
      "url": "/_autogen/Namespaces/namespacebatt/",
      "visibility": "public"
    }
  ],
  "override": false,
  "parent": {
    "anchor": "#dir-batteries/async",
    "category": "dirs",
    "fullname": "batteries/async",
    "kind": "dir",
    "language": "",
    "name": "batteries/async",
    "refid": "dir_faaa2176564b41e79cedcf3028f42662",
    "title": "batteries/async",
    "url": "/_autogen/Files/dir_faaa2176564b41e79cedcf3028f42662/#dir-batteries/async",
    "visibility": "public"
  },
  "parentBreadcrumbs": [
    {
      "anchor": "#dir-batteries",
      "category": "dirs",
      "fullname": "batteries",
      "kind": "dir",
      "language": "",
      "name": "batteries",
      "refid": "dir_af4e2857c92a31b60ebae85174ebeccb",
      "title": "batteries",
      "url": "/_autogen/Files/dir_af4e2857c92a31b60ebae85174ebeccb/#dir-batteries",
      "visibility": "public"
    },
    {
      "anchor": "#dir-batteries/async",
      "category": "dirs",
      "fullname": "batteries/async",
      "kind": "dir",
      "language": "",
      "name": "batteries/async",
      "refid": "dir_faaa2176564b41e79cedcf3028f42662",
      "title": "batteries/async",
      "url": "/_autogen/Files/dir_faaa2176564b41e79cedcf3028f42662/#dir-batteries/async",
      "visibility": "public"
    }
  ],
  "programlisting": "//######=###=##=#=#=#=#=#==#==#====#+==#+==============+==+==+==+=+==+=+=+=+=+=+=+\n// Copyright 2021-2022 Anthony Paul Astolfi\n//\n#pragma once\n#ifndef BATTERIES_ASYNC_TASK_IMPL_HPP\n#define BATTERIES_ASYNC_TASK_IMPL_HPP\n\n#include <batteries/config.hpp>\n//\n#include <batteries/async/task.hpp>\n//\n\n#include <batteries/async/debug_info.hpp>\n#include <batteries/async/fake_time_service.hpp>\n#include <batteries/async/future.hpp>\n#include <batteries/async/watch.hpp>\n\n#include <batteries/logging.hpp>\n#include <batteries/no_destruct.hpp>\n#include <batteries/stream_util.hpp>\n\nnamespace batt {\n\nBATT_INLINE_IMPL i32 next_thread_id()\n{\n    static std::atomic<i32> id_{1000};\n    return id_.fetch_add(1);\n}\n\nBATT_INLINE_IMPL i32& this_thread_id()\n{\n    thread_local i32 id_ = next_thread_id();\n    return id_;\n}\n\n//=#=#==#==#===============+=+=+=+=++=++++++++++++++-++-+--+-+----+---------------\n// Task static methods.\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL usize& Task::nesting_depth()\n{\n    thread_local usize depth_ = 0;\n    return depth_;\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL i32 Task::next_id()\n{\n    static std::atomic<i32> id_{1};\n    return id_.fetch_add(1);\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL Task* Task::current_ptr()\n{\n    return Trampoline::get_current_task();\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL Task& Task::current()\n{\n    return *current_ptr();\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL auto Task::all_tasks() -> ConcurrentTaskList&\n{\n    static NoDestruct<ConcurrentTaskList> instance_;\n    return *instance_;\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL void Task::yield()\n{\n    Task* current_task = Task::current_ptr();\n    if (current_task) {\n        current_task->yield_impl();\n        return;\n    }\n\n    std::this_thread::yield();\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL /*static*/ Optional<usize> Task::current_stack_pos()\n{\n    Task* current_task = Task::current_ptr();\n    if (current_task) {\n        return current_task->stack_pos();\n    }\n    return None;\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL /*static*/ Optional<usize> Task::current_stack_pos_of(const volatile void* ptr)\n{\n    Task* current_task = Task::current_ptr();\n    if (current_task) {\n        return current_task->stack_pos_of(ptr);\n    }\n    return None;\n}\n\n//=#=#==#==#===============+=+=+=+=++=++++++++++++++-++-+--+-+----+---------------\n// Task instance methods.\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL Task::~Task() noexcept\n{\n    BATT_CHECK(!this->scheduler_);\n    BATT_CHECK(!this->self_) << [this](std::ostream& out) {\n        print_debug_info(this->debug_info, out);\n    };\n    BATT_CHECK(is_terminal_state(this->state_.load())) << \"state=\" << StateBitset{this->state_.load()};\n\n    this->parent_task_list_.unlink(*this);\n\n    Task::destroy_count().fetch_add(1);\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL void Task::pre_body_fn_entry(Continuation&& scheduler) noexcept\n{\n    BATT_VLOG(1) << \"Task{.name=\" << this->name_ << \",} created on thread \" << this_thread_id();\n\n    // Save the base address of the call stack.\n    //\n    volatile u8 base = 0;\n    this->stack_base_ = &base;\n\n    // Transfer control back to the Task ctor.  This Task will be scheduled to run (activated) at the end of\n    // the ctor.\n    //\n    this->suspend_count_ = this->suspend_count_ + 1;\n    this->scheduler_ = scheduler.resume();\n    this->resume_count_ = this->resume_count_ + 1;\n\n    BATT_VLOG(1) << \"Task{.name=\" << this->name_ << \",} started on thread \" << this_thread_id();\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL Continuation Task::post_body_fn_exit() noexcept\n{\n    // Wait for all child tasks to terminate.  IMPORTANT: this needs to happen here, before we return the\n    // `scheduler_`/`parent` Continuation, and before we set the kTerminated flag, because the join mechanism\n    // relies on Watch::await_equal, which requires this Task to still be in \"normal operation\" mode.\n    //\n    this->join_child_tasks();\n\n    Continuation parent = std::move(this->scheduler_);\n    BATT_CHECK(parent);\n\n    this->handle_event(kTerminated);\n\n    return parent;\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL void Task::join_child_tasks()\n{\n    try {\n        this->child_tasks_.await_empty();\n    } catch (...) {\n        BATT_PANIC() << \"this->child_tasks_.await_empty() exited via unhandled exception [task='\"\n                     << this->name_ << \"']: \" << boost::current_exception_diagnostic_information();\n    }\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL void Task::run_completion_handlers()\n{\n    BATT_CHECK(this->is_done());\n    BATT_CHECK(!this->scheduler_);\n    BATT_CHECK(!this->self_);\n\n    HandlerList<> local_handlers;\n    {\n        SpinLockGuard lock{this, kCompletionHandlersLock};\n        std::swap(this->completion_handlers_, local_handlers);\n        {\n            // Set a state bit to make sure that there is no window of time where it is possible to add a\n            // new handler after this lambda executes, but before `this->is_done()` returns true.\n            //\n            // IMPORTANT: This must be the only place we set the kCompletionHandlersClosed bit, AND it must be\n            // _after_ we have swapped `this->completion_handlers_` with `local_handlers`!\n            //\n            const state_type prior_state = this->state_.fetch_or(kCompletionHandlersClosed);\n            BATT_CHECK_EQ(prior_state & kCompletionHandlersClosed, state_type(0))\n                << BATT_INSPECT(Task::StateBitset{prior_state});\n        }\n    }\n\n    invoke_all_handlers(&local_handlers);\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL void Task::wait_for_run_completion_handlers()\n{\n    // Fast path: since we know that kCompletionHandlersClosed is only set once, while holding the\n    // kCompletionHandlersLock (see the BATT_CHECK on `prior_state` in `run_completion_handlers()`), if we see\n    // the closed bit set without the lock bit set, then we know we are strictly _after_\n    // `run_completion_handlers() releasing its spin lock.  Therefore it is safe to delete the task!\n    {\n        const state_type observed_state = this->state_.load();\n        if ((observed_state & (kCompletionHandlersClosed | kCompletionHandlersLock)) ==\n            kCompletionHandlersClosed) {\n            return;\n        }\n    }\n\n    // Acquire a lock on completion handlers to make sure that there isn't a concurrent\n    // (racing) thread inside `Task::run_completion_handlers()`.  When `handler` is invoked,\n    // we must be _absolutely sure_ that it is safe to delete this Task.\n    //\n    for (;;) {\n        SpinLockGuard lock{this, kCompletionHandlersLock};\n        BATT_CHECK(this->is_done());\n        BATT_CHECK(this->completion_handlers_.empty());\n\n        // We have to be sure that Task::run_completion_handlers has been invoked and has gotten\n        // past the point where it will read anything from `this`.  Because the\n        // kCompletionHandlersClosed bit is only set at this point, but prior to releasing the\n        // kCompletionHandlersLock spin lock (inside run_completion_handlers), if we observe\n        // kCompletionHandlersClosed set while holding the spin lock, we know it is safe to invoke\n        // `handler` (which may cause `this` to be deleted).\n        //\n        if ((lock.prior_state() & kCompletionHandlersClosed) != 0) {\n            break;\n        }\n    }\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL ErrorCode Task::sleep_impl(const boost::posix_time::time_duration& duration)\n{\n    SpinLockGuard lock{this, kSleepTimerLock};\n\n    // The deadline_timer is lazily constructed.\n    //\n    if (!this->sleep_timer_) {\n        // First check to see if this Task's executor is configured to use the FakeTimeService.  If so, do\n        // a fake wait instead of a real one.\n        //\n        boost::asio::execution_context& context = this->ex_.context();\n        if (boost::asio::has_service<FakeTimeService>(context)) {\n            FakeTimeService& fake_time = boost::asio::use_service<FakeTimeService>(context);\n            const FakeTimeService::TimePoint expires_at = fake_time.now() + duration;\n            return this->await_impl<ErrorCode>([this, &fake_time, expires_at](auto&& handler) {\n                fake_time.async_wait(this->ex_, expires_at, BATT_FORWARD(handler));\n            });\n        }\n\n        this->sleep_timer_.emplace(this->ex_);\n    }\n\n    this->sleep_timer_->expires_from_now(duration);\n\n    return this->await_impl<ErrorCode>([&](auto&& handler) {\n        this->sleep_timer_->async_wait(BATT_FORWARD(handler));\n    });\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL usize Task::stack_pos() const\n{\n    volatile u8 pos = 0;\n    return this->stack_pos_of(&pos);\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL usize Task::stack_pos_of(const volatile void* ptr) const\n{\n    const u8* pos = (const u8*)ptr;\n    if (pos < this->stack_base_) {\n        return this->stack_base_ - pos;\n    } else {\n        return pos - this->stack_base_;\n    }\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL void Task::join()\n{\n    NoneType ignored = Task::await<NoneType>([this](auto&& handler) {\n        this->call_when_done(bind_handler(BATT_FORWARD(handler), [](auto&& handler) {\n            BATT_FORWARD(handler)(None);\n        }));\n    });\n    (void)ignored;\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL Task::IsDone Task::try_join()\n{\n    return this->is_done();\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL Task::IsDone Task::is_done() const\n{\n    return IsDone{Task::is_terminal_state(this->state_.load())};\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL bool Task::wake()\n{\n    SpinLockGuard lock{this, kSleepTimerLock};\n\n    if (this->sleep_timer_) {\n        ErrorCode ec;\n        this->sleep_timer_->cancel(ec);\n        if (!ec) {\n            return true;\n        }\n    }\n    return false;\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL void Task::handle_event(u32 event_mask)\n{\n    const u32 new_state = this->state_.fetch_or(event_mask) | event_mask;\n\n    if (is_ready_state(new_state)) {\n        const bool force_post = this->is_preempted_;\n        this->is_preempted_ = false;\n        this->schedule_to_run(new_state, force_post);\n        //\n    } else if (is_terminal_state(new_state)) {\n        BATT_CHECK_EQ(Task::current_ptr(), nullptr);\n        BATT_CHECK(!this->self_);\n        BATT_CHECK(!this->scheduler_);\n\n        BATT_VLOG(1) << \"[Task] \" << this->name_ << \" exiting\";\n\n        this->run_completion_handlers();\n        //\n        // IMPORTANT: there must be no access of `this` after `run_completion_handlers()`, since one of\n        // the completion handlers may have deleted the Task object.\n    }\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL void Task::schedule_to_run(u32 observed_state, bool force_post)\n{\n    for (;;) {\n        if (!is_ready_state(observed_state)) {\n            return;\n        }\n        const u32 target_state = observed_state & ~(kSuspended | kNeedSignal | kHaveSignal);\n        if (this->state_.compare_exchange_weak(observed_state, target_state)) {\n            break;\n        }\n    }\n\n    BATT_CHECK(is_ready_state(observed_state));\n    BATT_CHECK(this->self_);\n\n    if (!force_post && Task::nesting_depth() < kMaxNestingDepth) {\n        ++Task::nesting_depth();\n        auto on_scope_exit = batt::finally([] {\n            --Task::nesting_depth();\n        });\n        this->activate_via_dispatch();\n    } else {\n        this->activate_via_post();\n    }\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL Task::IsDone Task::run()\n{\n    // If the sleep timer lock was held *the last time* we yielded control, then re-acquire it now.\n    //\n    u32 observed_state = this->state_.load();\n    if (observed_state & kSleepTimerLockSuspend) {\n        for (;;) {\n            if (observed_state & kSleepTimerLock) {\n                observed_state = this->state_.load();\n                continue;\n            }\n            const u32 target_state = (observed_state & ~kSleepTimerLockSuspend) | kSleepTimerLock;\n            if (this->state_.compare_exchange_weak(observed_state, target_state)) {\n                break;\n            }\n        }\n    }\n\n    this->resume_impl();\n\n    // If the sleep timer lock was held *this time* when we yielded, then atomically release it and set\n    // the kSleepTimerLockSuspend bit so we re-acquire it next time.\n    //\n    observed_state = this->state_.load();\n    if (observed_state & kSleepTimerLock) {\n        for (;;) {\n            const u32 target_state = (observed_state & ~kSleepTimerLock) | kSleepTimerLockSuspend;\n            if (this->state_.compare_exchange_weak(observed_state, target_state)) {\n                break;\n            }\n        }\n    }\n\n    return IsDone{(observed_state & kTerminated) == kTerminated};\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL void Task::resume_impl()\n{\n    BATT_CHECK(this->self_) << StateBitset{this->state_.load()};\n\n    this->self_ = this->self_.resume();\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL void Task::yield_impl()\n{\n    BATT_CHECK(this->scheduler_) << StateBitset{this->state_.load()};\n\n    for (;;) {\n        this->suspend_count_ = this->suspend_count_ + 1;\n        this->scheduler_ = this->scheduler_.resume();\n        this->resume_count_ = this->resume_count_ + 1;\n\n        // If a stack trace has been requested, print it and suspend.\n        //\n        if (this->state_ & kStackTrace) {\n            this->stack_trace_.emplace();\n            continue;\n        }\n        break;\n    }\n\n    BATT_CHECK_EQ(Task::current_ptr(), this);\n    BATT_CHECK(this->scheduler_) << StateBitset{this->state_.load()};\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL u32 Task::spin_lock(u32 lock_mask)\n{\n    u32 prior_state = 0;\n\n    if (!this->try_spin_lock(lock_mask, prior_state)) {\n        for (;;) {\n            std::this_thread::yield();\n            if (this->try_spin_lock(lock_mask, prior_state)) {\n                break;\n            }\n        }\n    }\n\n    return prior_state;\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL bool Task::try_spin_lock(u32 lock_mask, u32& prior_state)\n{\n    prior_state = this->state_.fetch_or(lock_mask);\n    return (prior_state & lock_mask) == 0;\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL void Task::spin_unlock(u32 lock_mask)\n{\n    this->state_.fetch_and(~lock_mask);\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL i32 Task::backtrace_all(bool force, std::ostream& out)\n{\n    return Task::all_tasks().with_lock([&](TaskList& tasks) {\n        i32 i = 0;\n        out << std::endl;\n        for (auto& t : tasks) {\n            out << \"-- Task{id=\" << t.id() << \", name=\" << t.name_ << \", suspend=\" << t.suspend_count_\n                << \", resume=\" << t.resume_count_ << \"} -------------\" << std::endl;\n            if (!t.try_dump_stack_trace(force, out)) {\n                out << \" <no stack available>\" << std::endl;\n            }\n            out << std::endl;\n            ++i;\n        }\n        out << i << \" Tasks are active\" << std::endl;\n\n        print_all_threads_debug_info(out);\n\n        return i;\n    });\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL bool Task::try_dump_stack_trace(bool force, std::ostream& out)\n{\n    const auto dump_debug_info = [&] {\n        if (this->debug_info) {\n            out << \"DEBUG:\" << std::endl;\n            print_debug_info(this->debug_info, out);\n            out << std::endl;\n        }\n    };\n\n    u32 observed_state = this->state_.load();\n\n    const auto dump_state_bits = [&](std::ostream& out) {\n        if (is_terminal_state(observed_state)) {\n            out << \"(terminated) \";\n        } else if (is_running_state(observed_state)) {\n            out << \"(running) \";\n        } else if (is_ready_state(observed_state)) {\n            out << \"(ready) \";\n        } else if (observed_state & kStackTrace) {\n            out << \"(busy) \";\n        } else {\n            out << \"(suspended) \";\n        }\n        out << \"state=\" << StateBitset{this->state_}\n            << \" tims,hdlr,timr,dump,term,susp,have,need (0==running)\";\n    };\n\n    for (;;) {\n        if (is_running_state(observed_state) || is_ready_state(observed_state) ||\n            is_terminal_state(observed_state) || (observed_state & kStackTrace)) {\n            out << dump_state_bits << std::endl;\n            if (force) {\n                // This is dangerous, but sometimes you just need a clue about what is happening!\n                //\n                dump_debug_info();\n            }\n            return false;\n        }\n        const state_type target_state = observed_state | kStackTrace;\n        if (this->state_.compare_exchange_weak(observed_state, target_state)) {\n            break;\n        }\n    }\n\n    out << dump_state_bits << std::endl;\n\n    dump_debug_info();\n\n    this->resume_impl();\n\n    BATT_CHECK(this->stack_trace_);\n\n    out << *this->stack_trace_ << std::endl;\n    this->stack_trace_ = None;\n\n    observed_state = this->state_.load();\n    for (;;) {\n        const state_type target_state = (observed_state & ~kStackTrace) | kSuspended;\n\n        BATT_CHECK(!is_terminal_state(target_state))\n            << \"This should never happen because we check for terminal state above and calling \"\n               \"Task::resume_impl with the StackTrace bit set should never terminate the task.\";\n\n        if (this->state_.compare_exchange_weak(observed_state, target_state)) {\n            observed_state = target_state;\n            break;\n        }\n    }\n    if (is_ready_state(observed_state)) {\n        this->schedule_to_run(observed_state, /*force_post=*/true);\n    }\n    return true;\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL auto Task::make_activation_handler(bool via_post)\n{\n    return make_custom_alloc_handler(this->activate_memory_, [this, via_post] {\n        if (via_post) {\n            BATT_CHECK_EQ(Task::current_ptr(), nullptr);\n        }\n        Trampoline::activate_task(this);\n    });\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL void Task::activate_via_post()\n{\n    boost::asio::post(this->ex_, this->make_activation_handler(/*via_post=*/true));\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL void Task::activate_via_dispatch()\n{\n    boost::asio::dispatch(this->ex_, this->make_activation_handler(/*via_post=*/false));\n}\n\n//=#=#==#==#===============+=+=+=+=++=++++++++++++++-++-+--+-+----+---------------\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL void Task::Trampoline::activate_task(Task* task_to_activate)\n{\n    auto& self = per_thread_instance();\n\n    while (task_to_activate != nullptr) {\n        // If there is a task currently active on the current thread, then we will either soft-preempt it\n        // and reschedule the current task, or queue a deferred activation of `task_to_activate` via post.\n        //\n        if (self.current_task_ != nullptr) {\n            if (self.current_task_->get_priority() >= task_to_activate->get_priority()) {\n                // In this case, the current task gets to keep running on this thread because it has equal\n                // or higher priority.\n                //\n                task_to_activate->activate_via_post();\n            } else {\n                // In this case, we're going to force the current task to yield and re-activate it via\n                // post. By setting the Trampoline's `next_to_run_` to the task that has preempted it, we\n                // arrange for `task_to_activate` to be run after the current task yields.  Because there\n                // is a current task and Task::run() may only be called from Trampoline::activate_task,\n                // there must be a call to `activate_task` in the current task's scheduling context, so by\n                // yielding, we allow that call to run `task_to_activate`.\n                //\n                BATT_CHECK_EQ(self.next_to_run_, nullptr);\n                self.next_to_run_ = task_to_activate;\n                self.current_task_->is_preempted_ = true;\n                self.current_task_->yield_impl();\n            }\n            return;  // continue running `current_task`.\n        }\n        // else (self.current_task_ == nullptr)\n\n        {\n            BATT_CHECK_EQ(self.current_task_, nullptr);\n\n            self.current_task_ = task_to_activate;\n            auto on_scope_exit = finally([&self, activated_task = task_to_activate] {\n                BATT_CHECK_EQ(self.current_task_, activated_task);\n                self.current_task_ = nullptr;\n                activated_task->handle_event(kSuspended);\n            });\n\n            task_to_activate->run();\n        }\n\n        task_to_activate = self.next_to_run_;\n        self.next_to_run_ = nullptr;\n    }\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL Task* Task::Trampoline::get_current_task()\n{\n    return Task::Trampoline::per_thread_instance().current_task_;\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL auto Task::Trampoline::per_thread_instance() -> Trampoline&\n{\n    thread_local Trampoline instance;\n    return instance;\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL void Task::ConcurrentTaskList::push_back(Task& task)\n{\n    BATT_CHECK(!task.is_linked());\n\n    this->link_count_.fetch_add(1);\n    std::unique_lock<std::mutex> lock{this->mutex_};\n    this->task_list_.push_back(task);\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL void Task::ConcurrentTaskList::unlink(Task& task)\n{\n    if (!task.is_linked()) {\n        return;\n    }\n    {\n        std::unique_lock<std::mutex> lock{this->mutex_};\n        task.unlink();\n    }\n    this->unlink_count_.fetch_add(1);\n}\n\n//==#==========+==+=+=++=+++++++++++-+-+--+----- --- -- -  -  -   -\n//\nBATT_INLINE_IMPL void Task::ConcurrentTaskList::await_empty()\n{\n    i64 observed_unlink_count = this->unlink_count_.get_value();\n\n    while (observed_unlink_count != this->link_count_.load()) {\n        BATT_CHECK_LT(observed_unlink_count, this->link_count_.load())\n            << \"The link_count and unlink_count should never go backwards, and unlink_count should never get \"\n               \"ahead of the link_count!\";\n\n        StatusOr<i64> status = this->unlink_count_.await_not_equal(observed_unlink_count);\n        if (!status.ok()) {\n            break;\n        }\n        BATT_CHECK_GE(*status, observed_unlink_count) << \"unlink_count should never go backwards!\";\n        observed_unlink_count = *status;\n    }\n}\n\n}  // namespace batt\n\n#endif  // BATTERIES_ASYNC_TASK_IMPL_HPP",
  "refid": "task__impl_8hpp",
  "static": false,
  "strong": false,
  "title": "batteries/async/task_impl.hpp",
  "url": "/_autogen/Files/task__impl_8hpp/#file-task-impl.hpp",
  "visibility": "public"
}